{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nv = CountVectorizer()\nv.fit([\"Thor Hathodawala is looking for a job\"])\nv.vocabulary_","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:11:20.273485Z","iopub.execute_input":"2025-01-15T22:11:20.273973Z","iopub.status.idle":"2025-01-15T22:11:20.283269Z","shell.execute_reply.started":"2025-01-15T22:11:20.273945Z","shell.execute_reply":"2025-01-15T22:11:20.281982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"v = CountVectorizer(ngram_range=(1,3))\nv.fit([\"Thor Hathodawala is looking for a job\"])\nv.vocabulary_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:13:01.072109Z","iopub.execute_input":"2025-01-15T22:13:01.072464Z","iopub.status.idle":"2025-01-15T22:13:01.080515Z","shell.execute_reply.started":"2025-01-15T22:13:01.072438Z","shell.execute_reply":"2025-01-15T22:13:01.079583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corpus = [\n    \"Thor ate pizza\",\n    \"Loki is tall\",\n    \"Loki is eating pizza\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:13:36.023142Z","iopub.execute_input":"2025-01-15T22:13:36.023516Z","iopub.status.idle":"2025-01-15T22:13:36.028468Z","shell.execute_reply.started":"2025-01-15T22:13:36.023483Z","shell.execute_reply":"2025-01-15T22:13:36.027434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import spacy\n\n# load english language model and create nlp object from it\nnlp = spacy.load(\"en_core_web_sm\") \n\ndef preprocess(text):\n    # remove stop words and lemmatize the text\n    doc = nlp(text)\n    \n    return \" \".join([token.lemma_ for token in doc \n                     if (not token.is_stop) and (not token.is_punct)]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:15:11.386740Z","iopub.execute_input":"2025-01-15T22:15:11.387138Z","iopub.status.idle":"2025-01-15T22:15:21.278343Z","shell.execute_reply.started":"2025-01-15T22:15:11.387106Z","shell.execute_reply":"2025-01-15T22:15:21.277217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for text in corpus:\n    print(preprocess(text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T22:15:26.853612Z","iopub.execute_input":"2025-01-15T22:15:26.854174Z","iopub.status.idle":"2025-01-15T22:15:26.908785Z","shell.execute_reply.started":"2025-01-15T22:15:26.854143Z","shell.execute_reply":"2025-01-15T22:15:26.907697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}